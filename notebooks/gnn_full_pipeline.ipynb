{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __PROTACSplitter__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from protacdataset import ProtacLoader\n",
    "from protacsplitter import PROTACSplitter\n",
    "\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data_curation_augmentation_splitting_functions import (compute_countMorgFP,\n",
    "                                                            make_graph_with_pos)\n",
    "from pipeline_functions import (aggregate_output_all_epochs,\n",
    "                                aggregate_metrics_at_epoch, \n",
    "                                get_best_epoch,\n",
    "                                avg,\n",
    "                                aggregate_metrics_for_crossfold,\n",
    "                                crossfolds_avg_std_at_epoch,\n",
    "                                geo_mean)\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "import statistics\n",
    "\n",
    "\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "pd.set_option('display.max_columns', 1000, 'display.width', 2000, 'display.max_colwidth', 100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train: 952, 2856, 9520\n",
    "#Val. : 238, 714,  2380\n",
    "\n",
    "split_idx = 0\n",
    "\n",
    "butina_cutoff = \"0.33\"\n",
    "\n",
    "path_substr = {\n",
    "    \"Train\":            {'id': \"train\",             'n': \"952\",    'butina': butina_cutoff},\n",
    "    \"Validation\":       {'id': \"val\",               'n': \"238\",    'butina': butina_cutoff},\n",
    "}\n",
    "\n",
    "test_paths_substr_split_to_n = { \n",
    "    \"test_protac\":      {0: 108,    1: 108,     2: 108},\n",
    "    \"test_poi\":         {0: 70,     1: 70,      2: 60},\n",
    "    \"test_linker\":      {0: 135,    1: 135,     2: 135},\n",
    "    \"test_e3\":          {0: 75,     1: 50,      2: 50}, \n",
    "    \"test_poilinker\":   {0: 135,    1: 135,     2: 135},\n",
    "    \"test_poie3\":       {0: 70,     1: 70,      2: 60},\n",
    "    \"test_e3linker\":    {0: 135,    1: 135,     2: 135}, \n",
    "}\n",
    "\n",
    "\n",
    "test_paths_substr = {\n",
    "    \"Test PROTAC\":      {'id': \"test_protac\",         'butina': butina_cutoff},\n",
    "    \"Test Warhead\":         {'id': \"test_poi\",            'butina': butina_cutoff},\n",
    "    \"Test Linker\":      {'id': \"test_linker\",         'butina': butina_cutoff},\n",
    "    \"Test E3\":          {'id': \"test_e3\",             'butina': butina_cutoff},\n",
    "    \"Test W-Linker\":   {'id': \"test_poilinker\",     'butina': butina_cutoff},\n",
    "    \"Test W-E3\":       {'id': \"test_poie3\",         'butina': butina_cutoff},\n",
    "    \"Test E3Linker\":    {'id': \"test_e3linker\",       'butina': butina_cutoff}\n",
    "\n",
    "}\n",
    "\n",
    "dataset_paths = {dataset_name: f\"../data/augmented/{substr_dict['id']}_{substr_dict['n']}_ButinaClusterCutoff_{substr_dict['butina']}.csv\" for dataset_name, substr_dict in path_substr.items()}\n",
    "dataset_test_paths = {dataset_name: f\"../data/augmented/{substr_dict['id']}_split{split_idx}_ButinaClusterCutoff_{substr_dict['butina']}.csv\" for dataset_name, substr_dict in test_paths_substr.items()}\n",
    "dataset_paths.update(dataset_test_paths)\n",
    "\n",
    "\n",
    "chosen_dataset_paths = dataset_paths\n",
    "\n",
    "dataset_names = chosen_dataset_paths.keys()\n",
    "\n",
    "\n",
    "\n",
    "model_type=\"link_pred\" # node_pred link_pred boundary_pred\n",
    "node_descriptors = \"rdkit\" #ones, empty, rdkit\n",
    "graph_descriptors = [ \"betweenness\", \"closeness\"] # \"betweenness\", \"closeness\", \"local_eigenvectors_x\"\n",
    "model_crossfold=False\n",
    "save_datasets = False \n",
    "load_datasets = False\n",
    "precompute_splits=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_crossfold:\n",
    "    num_crossfolds = 5\n",
    "else:\n",
    "    num_crossfolds = 1\n",
    "ProtacDataset_loader = ProtacLoader(dataset_paths=chosen_dataset_paths, model_type=model_type, node_descriptors=node_descriptors, graph_descriptors=graph_descriptors, model_crossfold=model_crossfold)\n",
    "if not load_datasets:\n",
    "    datasets_dict = ProtacDataset_loader.initialize_datasets(dataframes=ProtacDataset_loader.load_dataframes(),\n",
    "                                                                num_crossfolds=num_crossfolds, precompute_splits=precompute_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "now_str = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "if save_datasets:\n",
    "    ProtacDataset_loader.save_datasets_to_file(dataset_path=f'data_{model_type}_{graph_descriptors}_split{split_idx}_{now_str}.pickle')\n",
    "if load_datasets:\n",
    "    datasets_dict = ProtacDataset_loader.load_datasets_from_file(dataset_path=f\"link_pred_{graph_descriptors}_split{split_idx}.pickle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Hyperparameters ---------------------\n",
    "    \n",
    "num_layers = 9\n",
    "layer_sizes = 250\n",
    "layer_dims = [layer_sizes]*num_layers # [trial.suggest_categorical(f'layer_dim_{i}', layer_sizes) for i in range(num_layers)]\n",
    "dropout_rate = 5.9e-3\n",
    "\n",
    "gnn_layer_type = 'TransformerConv'\n",
    "\n",
    "use_batch_normalization = False\n",
    "use_skip_connections = False\n",
    "use_graph_normalization = True\n",
    "use_edge_information = True if gnn_layer_type == 'TransformerConv' else False\n",
    "output_depth = 3\n",
    "\n",
    "lr = 8e-5\n",
    "batch_size = 1\n",
    "\n",
    "weight_class_loss = 0.1 \n",
    "\n",
    "\n",
    "\n",
    "# --------------------- Training parameters ---------------------\n",
    "\n",
    "epochs = 2\n",
    "max_epochs = 1000\n",
    "\n",
    "#Libraries set to None, as they are not important during optimization\n",
    "e3_library = pd.read_csv('../../data/e3_trainval_substructures_without_attachment.csv')[\"E3 SMILES\"].to_list()\n",
    "poi_library = pd.read_csv('../../data/poi_trainval_substructures_without_attachment.csv')[\"POI SMILES\"].to_list()\n",
    "\n",
    "#Early stopping parameters\n",
    "val_early_stopping = True #model looks back 2*n epochs to decide if it shall continue or stop, depending on validation loss. IF median has increased => Stop.\n",
    "median_over_n_val_losses = None\n",
    "min_over_n_val_losses = 10\n",
    "\n",
    "shift = 0.6 # vary this by hand for different models to set various early stopping criteria. Set to 1 to disable this feature\n",
    "stop_if_val_acc_below_x_at_n_list = [ #{'val_frac_criteria': 0.42, 'n_epochs': 1}, # good cutoff for node predictions\n",
    "                                                {'val_frac_criteria': 0.5-shift, 'n_epochs': 1}, #{'val_frac_criteria': 0.7, 'n_epochs': 2},\n",
    "                                                {'val_frac_criteria': 0.65-shift, 'n_epochs': 2}, # {'val_frac_criteria': 0.8, 'n_epochs': 3}, \n",
    "                                                {'val_frac_criteria': 0.7-shift, 'n_epochs': 3},# {'val_frac_criteria': 0.9, 'n_epochs': 4}, \n",
    "                                                {'val_frac_criteria': 0.75-shift, 'n_epochs': 4},#{'val_frac_criteria': 0.65, 'n_epochs': 8},\n",
    "                                                {'val_frac_criteria': 0.8-shift, 'n_epochs': 5},\n",
    "                                                {'val_frac_criteria': 0.825-shift, 'n_epochs': 6},\n",
    "                                                {'val_frac_criteria': 0.85-shift, 'n_epochs': 7},\n",
    "                                                {'val_frac_criteria': 0.875-shift, 'n_epochs': 8},\n",
    "                                                {'val_frac_criteria': 0.9-shift, 'n_epochs': 9}] #[x,n]   #if below 60% accuracy at 5 epochs, abort: x% at n epochs\n",
    "    \n",
    "# Model training parameters\n",
    "compute_pretrained_values = False \n",
    "compute_rand_accuracy = False\n",
    "\n",
    "param_to_opt = [\"accuracy\"], #[None],  \"accuracy\", \"recall\", \"precision\", \"f1\",                 if is set to [None], all evaluation metrics will be calculated\n",
    "\n",
    "#------------\n",
    "\n",
    "save_model_and_output = False\n",
    "\n",
    "compute_datasets_dict=True\n",
    "if 'datasets_dict' in locals():\n",
    "    compute_datasets_dict=False\n",
    "\n",
    "states = []\n",
    "outputs = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model (validate, no testsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    if compute_datasets_dict:\n",
    "        dataset_paths = {dataset_name: f\"../data/augmented/{substr_dict['id']}_{substr_dict['n']}_ButinaClusterCutoff{substr_dict['butina']}.csv\" for dataset_name, substr_dict in path_substr.items()}\n",
    "        dataset_paths.update(dataset_test_paths)\n",
    "\n",
    "        ProtacDataset_loader = ProtacLoader(dataset_paths=chosen_dataset_paths, model_type=model_type, node_descriptors=node_descriptors, graph_descriptors=graph_descriptors, model_crossfold=model_crossfold)\n",
    "        datasets_dict = ProtacDataset_loader.initialize_datasets(dataframes=ProtacDataset_loader.load_dataframes(),\n",
    "                                                                        num_crossfolds=1, precompute_splits=precompute_splits)\n",
    "        compute_datasets_dict=True\n",
    "        now = datetime.now()\n",
    "        now_str = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "\n",
    "\n",
    "    # --------------------- Model initialization and training ---------------------\n",
    "    \n",
    "    #Initialize model\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #\"cpu\") ## cuda makes the size of the network no longer matter in terms of epoch-time?! (64=1024 dimensions) On cpu it is 7 s vs 1min 30 seconds. GPU: 14 s vs 14 s\n",
    "        \n",
    "    train_key = \"Train\"\n",
    "    val_key = \"Validation\"\n",
    "    node_feature_dim = datasets_dict[train_key].num_node_features\n",
    "\n",
    "    output_layer_config = [{\n",
    "            'type': \"linear_symmetric\",  # Indicates symmetric processing but not global\n",
    "            'in_features': -1,  # Input features to the first output layer\n",
    "            'intermediate_features': layer_dims[0],  # Size for the middle layer in the sequence\n",
    "            'out_features': 3,  # Size for the final classification/prediction layer\n",
    "            'depth': output_depth,  # Total number of layers in this sequence\n",
    "        }]\n",
    "\n",
    "\n",
    "    boundary_layer_config = [{\n",
    "            'type': \"linear_symmetric\",  # Indicates the use of symmetric and global adjustments\n",
    "            'in_features': -1,  # Input features to the first boundary layer\n",
    "            'intermediate_features': layer_dims[0],  # Intermediate layer size (if applicable)\n",
    "            'out_features': 2,  # Final output size for boundary prediction\n",
    "            'depth': output_depth,  # Total number of layers in this sequence\n",
    "        }]\n",
    "\n",
    "    init_params = {\n",
    "        'model_type': model_type,\n",
    "        'node_feature_dim': node_feature_dim, \n",
    "        'device': device,\n",
    "        'num_predicted_classes': 3,\n",
    "        \n",
    "        'num_layers': num_layers,\n",
    "        'layer_dims': layer_dims,\n",
    "        'final_layer_dim': layer_dims[-1] if model_type==\"link_pred\" else 3,\n",
    "        'gnn_layer_type': gnn_layer_type,\n",
    "        \n",
    "        #TransformerConv parameters. Currently set to default values.\n",
    "        'TransformerConvHeads': 1,\n",
    "        'TransformerConvBeta': False,\n",
    "        'TransformerConvDropout': 0,\n",
    "\n",
    "        #Possible to add the L1 and L2 norm of model parameters to the loss (it is normalized (divided) by the number of modelparameters before)\n",
    "        'regularization_types': [], # ['L1_model_params', 'L2_model_params']\n",
    "        'dropout_rate': dropout_rate,\n",
    "        \n",
    "        'use_skip_connections': use_skip_connections,\n",
    "        'use_graph_normalization': use_graph_normalization,\n",
    "        'use_edge_information': use_edge_information,\n",
    "        'use_batch_normalization': use_batch_normalization,\n",
    "\n",
    "        'output_layer_config': output_layer_config,\n",
    "        'boundary_layer_config': boundary_layer_config\n",
    "    }    \n",
    "\n",
    "    model = PROTACSplitter(init_params=init_params)\n",
    "\n",
    "\n",
    "    train_params = {\n",
    "        'datasets_dict': datasets_dict,\n",
    "        'optimizer': optim.Adam,\n",
    "        'lr': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'criterion': nn.CrossEntropyLoss(reduction='sum'),\n",
    "        'epochs': epochs,\n",
    "        'max_epochs': max_epochs,\n",
    "        'val_early_stopping': val_early_stopping,\n",
    "        'median_over_n_val_losses': median_over_n_val_losses,\n",
    "        'min_over_n_val_losses': min_over_n_val_losses,\n",
    "        'stop_if_val_acc_below_x_at_n_list': stop_if_val_acc_below_x_at_n_list,\n",
    "        'print_every_n_epochs': 1,\n",
    "        'compute_pretrained_values': compute_pretrained_values,\n",
    "        'compute_rand_accuracy': compute_rand_accuracy,\n",
    "        'e3_library': e3_library,\n",
    "        'poi_library': poi_library,\n",
    "        'fp_function': compute_countMorgFP,\n",
    "        'param_to_opt': param_to_opt, #[None],  accuracy, recall, precision, f1,                 if is set to [None], all evaluation metrics will be calculated\n",
    "        'weight_class_loss': weight_class_loss #weighting between row-loss (bondclass-loss) and column-loss.\n",
    "    }\n",
    "\n",
    "    # Adjust use_batch_normalization based on batch_size\n",
    "    if train_params['batch_size'] > 1:\n",
    "        init_params['use_batch_normalization'] = True\n",
    "\n",
    "    # Model factory function\n",
    "    def create_model(init_params):\n",
    "        model = PROTACSplitter(init_params=init_params)\n",
    "        model.to(init_params['device'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    model = create_model(init_params)\n",
    "    output = model.train_model(train_params = train_params)\n",
    "    outputs.append(output)\n",
    "    finishing_time = datetime.now()\n",
    "    timedelta_to_train_model = finishing_time - start_time\n",
    "    minutes_to_train_model = timedelta_to_train_model.seconds/(60*num_crossfolds)\n",
    "    minutes_per_epoch = minutes_to_train_model/(model.epoch+int(train_params['compute_pretrained_values']))\n",
    "        \n",
    "\n",
    "    print(f\"Training started at {start_time} and finished at {finishing_time}\")\n",
    "    print(f\"Minutes per epoch: {minutes_per_epoch}\")\n",
    "\n",
    "\n",
    "    epochs = model.epoch #new max-epoch. As to not run one model for more epochs than a previous model have stopped at before, as these epochs WILL be discard\n",
    "\n",
    "\n",
    "\n",
    "    import pickle\n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "    output_comment = f\"{model_type}\"\n",
    "\n",
    "    \n",
    "\n",
    "    if save_model_and_output:\n",
    "        data = {'model': model, 'output': output}\n",
    "        with open(f\"../data/model_outputs/{model.model_type}_{graph_descriptors}_{output_comment}_{now_str}\", 'wb') as file:\n",
    "            pickle.dump(data, file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and test on the 3 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for split_idx in [0, 1, 2]:\n",
    "    if compute_datasets_dict:\n",
    "        dataset_paths = {dataset_name: f\"../data/augmented/{substr_dict['id']}_{substr_dict['n']}_ButinaClusterCutoff{substr_dict['butina']}.csv\" for dataset_name, substr_dict in path_substr.items()}\n",
    "        dataset_test_paths = {dataset_name: f\"../data/augmented/{substr_dict['id']}_split{split_idx}_ButinaClusterCutoff{substr_dict['butina']}.csv\" for dataset_name, substr_dict in test_paths_substr.items()}\n",
    "        dataset_paths.update(dataset_test_paths)\n",
    "\n",
    "        ProtacDataset_loader = ProtacLoader(dataset_paths=chosen_dataset_paths, model_type=model_type, node_descriptors=node_descriptors, graph_descriptors=graph_descriptors, model_crossfold=model_crossfold)\n",
    "        datasets_dict = ProtacDataset_loader.initialize_datasets(dataframes=ProtacDataset_loader.load_dataframes(),\n",
    "                                                                        num_crossfolds=1, precompute_splits=precompute_splits)\n",
    "        compute_datasets_dict=True\n",
    "        now = datetime.now()\n",
    "        now_str = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "        if save_datasets:\n",
    "            ProtacDataset_loader.save_datasets_to_file(dataset_path=f'data_{model_type}_{graph_descriptors}_split{split_idx}_{now_str}.pickle')\n",
    "   \n",
    "    \n",
    "\n",
    "    # --------------------- Model initialization and training ---------------------\n",
    "    \n",
    "    #Initialize model\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #\"cpu\") ## cuda makes the size of the network no longer matter in terms of epoch-time?! (64=1024 dimensions) On cpu it is 7 s vs 1min 30 seconds. GPU: 14 s vs 14 s\n",
    "        \n",
    "    train_key = \"Train\"\n",
    "    val_key = \"Validation\"\n",
    "    node_feature_dim = datasets_dict[train_key].num_node_features\n",
    "\n",
    "    output_layer_config = [{\n",
    "            'type': \"linear_symmetric\",  # Indicates symmetric processing but not global\n",
    "            'in_features': -1,  # Input features to the first output layer\n",
    "            'intermediate_features': layer_dims[0],  # Size for the middle layer in the sequence\n",
    "            'out_features': 3,  # Size for the final classification/prediction layer\n",
    "            'depth': output_depth,  # Total number of layers in this sequence\n",
    "        }]\n",
    "\n",
    "\n",
    "    boundary_layer_config = [{\n",
    "            'type': \"linear_symmetric\",  # Indicates the use of symmetric and global adjustments\n",
    "            'in_features': -1,  # Input features to the first boundary layer\n",
    "            'intermediate_features': layer_dims[0],  # Intermediate layer size (if applicable)\n",
    "            'out_features': 2,  # Final output size for boundary prediction\n",
    "            'depth': output_depth,  # Total number of layers in this sequence\n",
    "        }]\n",
    "\n",
    "    init_params = {\n",
    "        'model_type': model_type,\n",
    "        'node_feature_dim': node_feature_dim, \n",
    "        'device': device,\n",
    "        'num_predicted_classes': 3,\n",
    "        \n",
    "        'num_layers': num_layers,\n",
    "        'layer_dims': layer_dims,\n",
    "        'final_layer_dim': layer_dims[-1] if model_type==\"link_pred\" else 3,\n",
    "        'gnn_layer_type': gnn_layer_type,\n",
    "        \n",
    "        #TransformerConv parameters. Currently set to default values.\n",
    "        'TransformerConvHeads': 1,\n",
    "        'TransformerConvBeta': False,\n",
    "        'TransformerConvDropout': 0,\n",
    "\n",
    "        #Possible to add the L1 and L2 norm of model parameters to the loss (it is normalized (divided) by the number of modelparameters before)\n",
    "        'regularization_types': [], # ['L1_model_params', 'L2_model_params']\n",
    "        'dropout_rate': dropout_rate,\n",
    "        \n",
    "        'use_skip_connections': use_skip_connections,\n",
    "        'use_graph_normalization': use_graph_normalization,\n",
    "        'use_edge_information': use_edge_information,\n",
    "        'use_batch_normalization': use_batch_normalization,\n",
    "\n",
    "        'output_layer_config': output_layer_config,\n",
    "        'boundary_layer_config': boundary_layer_config\n",
    "    }    \n",
    "\n",
    "    model = PROTACSplitter(init_params=init_params)\n",
    "\n",
    "\n",
    "    train_params = {\n",
    "        'datasets_dict': datasets_dict,\n",
    "        'optimizer': optim.Adam,\n",
    "        'lr': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'criterion': nn.CrossEntropyLoss(reduction='sum'),\n",
    "        'epochs': epochs,\n",
    "        'max_epochs': max_epochs,\n",
    "        'val_early_stopping': val_early_stopping,\n",
    "        'median_over_n_val_losses': median_over_n_val_losses,\n",
    "        'min_over_n_val_losses': min_over_n_val_losses,\n",
    "        'stop_if_val_acc_below_x_at_n_list': stop_if_val_acc_below_x_at_n_list,\n",
    "        'print_every_n_epochs': 1,\n",
    "        'compute_pretrained_values': compute_pretrained_values,\n",
    "        'compute_rand_accuracy': compute_rand_accuracy,\n",
    "        'e3_library': e3_library,\n",
    "        'poi_library': poi_library,\n",
    "        'fp_function': compute_countMorgFP,\n",
    "        'param_to_opt': param_to_opt, \n",
    "        'weight_class_loss': weight_class_loss #weighting between row-loss (bondclass-loss) and column-loss.\n",
    "    }\n",
    "\n",
    "    # Adjust use_batch_normalization based on batch_size\n",
    "    if train_params['batch_size'] > 1:\n",
    "        init_params['use_batch_normalization'] = True\n",
    "\n",
    "    # Model factory function\n",
    "    def create_model(init_params):\n",
    "        model = PROTACSplitter(init_params=init_params)\n",
    "        model.to(init_params['device'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    model = create_model(init_params)\n",
    "    output = model.train_model(train_params = train_params)\n",
    "    outputs.append(output)\n",
    "    finishing_time = datetime.now()\n",
    "    timedelta_to_train_model = finishing_time - start_time\n",
    "    minutes_to_train_model = timedelta_to_train_model.seconds/(60*num_crossfolds)\n",
    "    minutes_per_epoch = minutes_to_train_model/(model.epoch+int(train_params['compute_pretrained_values']))\n",
    "        \n",
    "\n",
    "    print(f\"Training started at {start_time} and finished at {finishing_time}\")\n",
    "    print(f\"Minutes per epoch: {minutes_per_epoch}\")\n",
    "\n",
    "\n",
    "    epochs = model.epoch #new max-epoch. As to not run one model for more epochs than a previous model have stopped at before, as these epochs WILL be discard\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "    output_comment = f\"{model_type}_split{split_idx}\"\n",
    "\n",
    "    \n",
    "\n",
    "    if save_model_and_output:\n",
    "        data = {'model': model, 'output': output}\n",
    "        with open(f\"../data/model_outputs/{model.model_type}_{graph_descriptors}_{output_comment}_{now_str}\", 'wb') as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    #\"\"\"\n",
    "    model_crossfold = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model_and_output and model_crossfold: #load the saved 3 splits\n",
    "    import pickle\n",
    "    import gc\n",
    "\n",
    "    identifying_comment = \"besthypparams_woLocEigen\"\n",
    "    chosen_experiment = \"link_pred_bestparams_woLocEigen_allmetrics\"\n",
    "\n",
    "\n",
    "\n",
    "    outputs = []\n",
    "    studies = {}\n",
    "    for split_idx, study_path in chosen_experiment.items():\n",
    "        p = f\"../../data/model_outputs/{study_path}\"\n",
    "        with open(p, 'rb') as file:\n",
    "            torch.cuda.empty_cache()\n",
    "            x = pickle.load(file)\n",
    "            outputs.append(x[\"output\"])\n",
    "            if split_idx != 2:\n",
    "                del x #sometimes all 3 models and outputs are too big for the GPU memory => Load and clean itterativly.\n",
    "                gc.collect\n",
    "        print(split_idx)\n",
    "\n",
    "            \n",
    "    model = x[\"model\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _---------------Best (average) epoch metrics-------------------_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifying_comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_crossfold:\n",
    "    measures_avg, measures_std, measures_concat = aggregate_metrics_for_crossfold(outputs=outputs, model=model)\n",
    "else:\n",
    "    aggregated_output = aggregate_output_all_epochs(output=output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best average epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = get_best_epoch(output=measures_avg if model_crossfold else aggregated_output, \n",
    "                       dataset= model.val_set_name, \n",
    "                       accuracy_origin=\"model\", \n",
    "                       structure=\"PROTAC\", \n",
    "                       metric_type=\"Accuracy\",\n",
    "                       model_crossfold = model_crossfold)\n",
    "\n",
    "print(f'Best epoch: {best_epoch}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(model.states[best_epoch-1])\n",
    "torch.save(model, 'protacsplitter_params.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display evaluation metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_crossfold:\n",
    "    avg_std_metrics = crossfolds_avg_std_at_epoch(outputs=outputs, epoch=best_epoch, dataset_names=list(outputs[0][\"metrics\"].keys()), print_df = True)\n",
    "else:\n",
    "    aggregated_metrics = aggregate_metrics_at_epoch(output=output, epoch=best_epoch)\n",
    "    aggregated_metrics_df = pd.DataFrame(aggregated_metrics)\n",
    "    row_names = [dataset_name for dataset_name in output['metrics'].keys()]\n",
    "    aggregated_metrics_df.index = row_names\n",
    "    print(aggregated_metrics_df.round(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots distributions at best epoch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PROTAC vs LIGANDS+LINKER accuracy distribution\n",
    "investigate accuracy of model type prediction and split prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_concat\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "num_datasets = len(acc_to_plot['metrics'])\n",
    "\n",
    "fig, axs = plt.subplots(1, num_datasets, figsize=(5*num_datasets,4), sharey=False)\n",
    "\n",
    "for dataset_name, ax in zip(acc_to_plot['metrics'].keys(), axs):\n",
    "\n",
    "    protac_accuracies = acc_to_plot['metrics'][dataset_name][\"model\"][\"PROTAC\"][\"Accuracy\"][best_epoch]  \n",
    "    ligand_linker_accuracies = acc_to_plot['metrics'][dataset_name][\"model\"][\"LIGANDS\"][\"Accuracy\"][best_epoch] \n",
    "\n",
    "    # Plotting the histograms\n",
    "    binwidth = 0.01\n",
    "    bins = list(np.arange(0, 1 + binwidth, binwidth))\n",
    "    ax.hist(protac_accuracies, range=(0,1), bins=bins, alpha=0.5, label='PROTAC', color='red')  # First histogram\n",
    "    ax.hist(ligand_linker_accuracies, range=(0,1), bins=bins, alpha=0.5, label='LIGANDS+LINKER', color='blue')   # Second histogram\n",
    "\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "    # Adding some plot details\n",
    "    #ax.xlabel('Accuracy')\n",
    "    #ax.ylabel('Frequency')\n",
    "    ax.title.set_text(f'Accuracy for {dataset_name} dataset')\n",
    "    #ax.legend()\n",
    "#\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin plot atoms wrong (TP+FN)\n",
    "Gives overview of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_concat\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "dataset_names = [\"Validation\", \"Test PROTAC\"]\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "\n",
    "    #dataset_name = \"Test PROTAC\"\n",
    "    accuracy_origin = \"model\"\n",
    "\n",
    "    structures_to_plot = [\"PROTAC\", \"LIGANDS\"]\n",
    "    renaming_dict = {\"PROTAC\": \"PROTAC\", \"LIGANDS\": \"Ligands & Linker\"}\n",
    "\n",
    "    substructure_atoms_wrong = {}\n",
    "    for substructure in acc_to_plot[\"metrics\"][dataset_name][accuracy_origin].keys():\n",
    "        if substructure not in structures_to_plot:\n",
    "            continue\n",
    "        if \"Atoms_wrong\" in acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][substructure]:\n",
    "            substructure_atoms_wrong[substructure] = []\n",
    "            for num_wrong, count in acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][substructure][\"Atoms_wrong\"][best_epoch].items():\n",
    "                substructure_atoms_wrong[substructure].extend([num_wrong]*count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Convert this mock data into a DataFrame\n",
    "    substructure_atoms_wrong_df = pd.DataFrame({renaming_dict[k]: pd.Series(v) for k, v in substructure_atoms_wrong.items()})\n",
    "    substructure_atoms_wrong_df_long = pd.melt(substructure_atoms_wrong_df, var_name='Atoms_wrong', value_name='Count wrong atoms')\n",
    "\n",
    "\n",
    "    # Separate the data\n",
    "    protac_data = substructure_atoms_wrong_df_long[substructure_atoms_wrong_df_long['Atoms_wrong'] == 'PROTAC']\n",
    "    remaining_data = substructure_atoms_wrong_df_long[substructure_atoms_wrong_df_long['Atoms_wrong'] != 'PROTAC']\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    # Plot \"PROTAC\" with cut=0 on the first subplot\n",
    "    sns.violinplot(x='Atoms_wrong', y='Count wrong atoms', data=substructure_atoms_wrong_df_long, cut=0, ax=ax)\n",
    "\n",
    "    # Adjustments for both subplots\n",
    "    ax.set_xlabel('')  # Remove the overall x-axis label\n",
    "    ax.tick_params(axis='x', length=0)  # Remove the x-ticks but keep the labels\n",
    "    # Keeping the tick labels unrotated\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(0)\n",
    "\n",
    "    # Remove spines for a cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # Set a common title for the figure\n",
    "    #fig.suptitle(f'Frequency & count of wrongly predicted atoms \\n{dataset_name}', fontsize=16)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_violin_{dataset_name}_{structures_to_plot}.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "    #fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_violin_{dataset_name}_{structures_to_plot}.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative barplot atoms wrong (normalized FP+FN)\n",
    "Answers detailed questions on how wrong/good it is. \n",
    "E.g. What fraction of predictions for a given structure have at most x atoms wrongly predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"Validation\", \"Test PROTAC\"] #list(acc_to_plot[\"metrics\"].keys()) #\n",
    "invert = True\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_concat\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    #dataset_name = \"Test PROTAC\"\n",
    "    accuracy_origin = \"model\"\n",
    "    substructure = \"LIGANDS\"\n",
    "\n",
    "\n",
    "\n",
    "    if model_crossfold:\n",
    "        atoms_wrong_to_plot = outputs\n",
    "    else:\n",
    "        atoms_wrong_to_plot = [output]\n",
    "\n",
    "    fractions_across_splits = {}\n",
    "    for split_idx, acc_to_plot in enumerate(atoms_wrong_to_plot):\n",
    "\n",
    "        atoms_wrong_occuracnes = list(acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][substructure][\"Atoms_wrong\"][best_epoch].keys())\n",
    "\n",
    "        total_number_of_protacs = sum(acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][substructure][\"Atoms_wrong\"][best_epoch].values())\n",
    "\n",
    "\n",
    "        cumulative_fraction = 0\n",
    "        cumulative_dict = {}\n",
    "        lowest_occurance = min(atoms_wrong_occuracnes)\n",
    "        highest_occurance = max(atoms_wrong_occuracnes)\n",
    "\n",
    "        for i in range(lowest_occurance, highest_occurance+1):\n",
    "            if i in acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][substructure][\"Atoms_wrong\"][best_epoch]:\n",
    "                cumulative_fraction += acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][substructure][\"Atoms_wrong\"][best_epoch][i]/total_number_of_protacs\n",
    "            cumulative_dict[i] = cumulative_fraction\n",
    "\n",
    "\n",
    "        max_atoms_wrong_to_plot = 10\n",
    "        fractions = list(cumulative_dict.values())[0:max_atoms_wrong_to_plot+1]\n",
    "        num_atoms_wrong = list(cumulative_dict.keys())[0:max_atoms_wrong_to_plot+1] \n",
    "\n",
    "        fractions_across_splits[split_idx] = fractions\n",
    "\n",
    "\n",
    "    average_fractions = []\n",
    "    std_fractions = []\n",
    "    for i in range(max_atoms_wrong_to_plot+1):\n",
    "        tmp = []\n",
    "        for split_idx, fractions in fractions_across_splits.items():\n",
    "            if i >= len(fractions):\n",
    "                correct_fraction = 1\n",
    "            else:\n",
    "                correct_fraction = fractions[i]\n",
    "            tmp.append(correct_fraction)\n",
    "\n",
    "        avg_tmp = 1-avg(tmp) if invert else avg(tmp)\n",
    "\n",
    "        average_fractions.append(avg_tmp)\n",
    "        std_fractions.append(statistics.stdev(tmp))\n",
    "        \n",
    "\n",
    "   # print(average_fractions)\n",
    "    # print(f'Fraction of predictions with 6 or fewer mispredicted atoms for {dataset_name}: {(1-average_fractions[6])*100}')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    plt.bar(num_atoms_wrong, average_fractions, color=\"skyblue\" )\n",
    "    plt.errorbar(num_atoms_wrong, average_fractions, yerr=std_fractions, fmt=\".\", color=\"k\" )\n",
    "    plt.ylim(bottom=0)\n",
    "    if average_fractions[0]> 0.5:\n",
    "        plt.ylim(top=1)\n",
    "    else:\n",
    "        plt.ylim(top=(average_fractions[0]+std_fractions[0])*1.3)\n",
    "    #plt.title(\"Cumulative fraction with at most x atoms wrong\")\n",
    "\n",
    "    plt.xlabel(\"Atoms wrong\")\n",
    "    plt.ylabel(\"Fraction of predictions\" )\n",
    "    plt.xticks(range(0, max_atoms_wrong_to_plot +1, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    invert_str = \"_inverted\" if invert else \"\"\n",
    "\n",
    "    #fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_cumulative_{dataset_name}_{substructure}{invert_str}.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "    #fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_cumulative_{dataset_name}_{substructure}{invert_str}.png', format='png', dpi=1200, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of Precision, Recall, F1 for substructures\n",
    "Plot at epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming output, dataset_name, epoch, accuracy_origin, structure_type are defined\n",
    "# For illustration, avg and median functions need to be defined or imported as well\n",
    "\n",
    "dataset_name = model.train_set_name\n",
    "accuracy_origin = \"model\"\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_concat\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "# Calculate the number of metrics to determine the grid size\n",
    "substructure_list = ['LIGANDS', 'POI', 'LINKER', 'E3']\n",
    "metrics_list = ['Precision', 'Recall']\n",
    "num_substructures = len(substructure_list)\n",
    "num_metrics = len(metrics_list)\n",
    "# Calculate grid size (for simplicity, creating a grid of 1 row)\n",
    "nrows = num_substructures\n",
    "ncols = num_metrics\n",
    "\n",
    "# Create subplot grid\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(5*ncols, 4*num_substructures), sharey=True, sharex=True) # Adjust figsize as needed\n",
    "if ncols == 1:  # If there's only one subplot, axs may not be an array\n",
    "    axs = [axs]\n",
    "\n",
    "binwidth = 0.01\n",
    "bins = list(np.arange(0, 1 + binwidth, binwidth))\n",
    "\n",
    "# Iterate over each metric and plot\n",
    "for axs_structure, structure_type in zip(axs, substructure_list):\n",
    "    ax_idx = 0\n",
    "    if structure_type not in substructure_list:\n",
    "        continue\n",
    "\n",
    "    for metric_type, epoch_metric_dict in acc_to_plot[\"metrics\"][dataset_name][accuracy_origin][structure_type].items():\n",
    "        if metric_type not in metrics_list:\n",
    "            continue\n",
    "        metric_values = epoch_metric_dict[best_epoch]\n",
    "\n",
    "        ax = axs_structure[ax_idx]\n",
    "        ax_idx += 1\n",
    "        ax.hist(metric_values, range=(0,1), bins=bins)\n",
    "\n",
    "        ax.set_title(f\"{metric_type} for {structure_type} in {dataset_name} from {accuracy_origin}.\\nAvg: {round(np.mean(metric_values),2)}, Median: {round(np.median(metric_values),2)}\")\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot barplot of Precision and recall for substructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_avg\n",
    "    std_to_plot = measures_std\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "group_labels = list(acc_to_plot[\"validity_fraction\"].keys())\n",
    "subcategories = ['Warhead', 'Linker', 'E3']  # For the legend\n",
    "colors = ['red', 'gray', 'blue']\n",
    "substructures_to_substructures = {'Warhead': \"POI\", 'Linker':\"LINKER\", 'E3': \"E3\"}\n",
    "metrics = [\"Precision\", \"Recall\"]\n",
    "\n",
    "# Set up the figure\n",
    "fig, axs = plt.subplots(figsize=(15, 10), nrows = 2, ncols=1, sharex=True)\n",
    "\n",
    "# Number of groups\n",
    "n_groups = len(group_labels)\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 1/(1+len(subcategories))\n",
    "\n",
    "# The x location for the groups\n",
    "indices = np.arange(n_groups)\n",
    "\n",
    "x_factor = 1.2\n",
    "\n",
    "# Plotting each group\n",
    "for metric, ax in zip(metrics, axs):\n",
    "\n",
    "\n",
    "\n",
    "    for i, category in enumerate(subcategories):\n",
    "        \n",
    "        vals = []\n",
    "        stds = []\n",
    "        for dataset_name in acc_to_plot[\"metrics\"].keys():\n",
    "            vals.append(acc_to_plot[\"metrics\"][dataset_name][\"model\"][substructures_to_substructures[category]][metric][best_epoch])\n",
    "            stds.append(std_to_plot[\"metrics\"][dataset_name][\"model\"][substructures_to_substructures[category]][metric][best_epoch])\n",
    "\n",
    "    # data = [validity_dict[validity_type][best_epoch] for ]\n",
    "        # The x location for the bars within each group\n",
    "        bar_positions = x_factor*indices + i * bar_width +bar_width/2\n",
    "        ax.bar(bar_positions, vals, width=bar_width, label=category, color=(colors[i],0.8))\n",
    "        ax.errorbar(bar_positions, vals, yerr=stds, fmt=\".\", color=(\"k\", 0.7))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Setting the x-ticks and labels for each group\n",
    "    plt.xticks(x_factor*indices + bar_width * 1.5, group_labels)\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.title.set_text(metric)\n",
    "\n",
    "\n",
    "    # Adding a legend\n",
    "    ax.legend()\n",
    "\n",
    "#fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_precision_recall.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "#fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_precision_recall.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PROTAC accuracy and ligands linker accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_avg\n",
    "    std_to_plot = measures_std\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "group_labels = list(acc_to_plot[\"validity_fraction\"].keys())\n",
    "subcategories = ['PROTAC', 'LIGANDS']  # For the legend\n",
    "colors = ['green', 'purple']\n",
    "substructures_to_substructures = {'PROTAC': \"PROTAC\", 'LIGANDS':\"Ligands&Linker\"}\n",
    "metrics = [\"Accuracy\"]\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(15, 5), nrows = 1, ncols=1, sharex=True)\n",
    "\n",
    "# Number of groups\n",
    "n_groups = len(group_labels)\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 1/(1+len(subcategories))\n",
    "\n",
    "# The x location for the groups\n",
    "indices = np.arange(n_groups)\n",
    "\n",
    "x_factor = 1.4\n",
    "\n",
    "# Plotting each group\n",
    "for metric in metrics:\n",
    "\n",
    "\n",
    "\n",
    "    for i, category in enumerate(subcategories):\n",
    "        \n",
    "        vals = []\n",
    "        stds = []\n",
    "        for dataset_name in acc_to_plot[\"metrics\"].keys():\n",
    "            vals.append(acc_to_plot[\"metrics\"][dataset_name][\"model\"][category][\"Accuracy\"][best_epoch])\n",
    "            stds.append(std_to_plot[\"metrics\"][dataset_name][\"model\"][category][\"Accuracy\"][best_epoch])\n",
    "\n",
    "    # data = [validity_dict[validity_type][best_epoch] for ]\n",
    "        # The x location for the bars within each group\n",
    "        bar_positions = x_factor*indices + i * bar_width +bar_width\n",
    "        ax.bar(bar_positions, vals, width=bar_width, label=substructures_to_substructures[category], color=(colors[i],0.9))\n",
    "        ax.errorbar(bar_positions, vals, yerr=stds, fmt=\".\", color=(\"k\", 0.7))\n",
    "\n",
    "    # Setting the x-ticks and labels for each group\n",
    "    plt.xticks(x_factor*indices + bar_width * 1.5, group_labels)\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.title.set_text(metric)\n",
    "\n",
    "\n",
    "    # Adding a legend\n",
    "    ax.legend()\n",
    "\n",
    "#fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_protac_ligandslinker_accuracy.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "#fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_protac_ligandslinker_accuracy.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot frequency of flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_avg\n",
    "    std_to_plot = measures_std\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "dataset_names = list(acc_to_plot[\"flip_fraction\"].keys())\n",
    "flip_fractions = [acc_to_plot[\"flip_fraction\"][dataset_name][best_epoch] for dataset_name in acc_to_plot[\"flip_fraction\"].keys()]\n",
    "flip_stds = [std_to_plot[\"flip_fraction\"][dataset_name][best_epoch] for dataset_name in std_to_plot[\"flip_fraction\"].keys()]\n",
    "#flip_stds\n",
    "# Creating the bar plot\n",
    "plt.figure(figsize=(15, 6))  # Optional: Specifies the figure size\n",
    "plt.bar(dataset_names, flip_fractions, color='skyblue')  # Creates the bar plot with names on the x-axis and values on the y-axis\n",
    "plt.errorbar(dataset_names, flip_fractions, yerr=flip_stds, fmt=\"o\", color=\"k\")\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('')  # X-axis label\n",
    "plt.ylabel('')  # Y-axis label\n",
    "plt.ylim(bottom=0)\n",
    "#plt.title('Flipped fraction of PROTACs')  # Plot title\n",
    "\n",
    "#plt.savefig(f'fig_results/{model.model_type}_{identifying_comment}_flipfraction.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "#plt.savefig(f'fig_results/{model.model_type}_{identifying_comment}_flipfraction.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot valid SMILES & splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_avg\n",
    "else:\n",
    "    acc_to_plot = output\n",
    "\n",
    "group_labels = list(acc_to_plot[\"validity_fraction\"].keys())\n",
    "subcategories = ['VALID SPLIT', 'POI SMILES', 'LINKER SMILES', 'E3 SMILES']  # For the legend\n",
    "colors = ['purple', 'red', 'green', 'blue']\n",
    "\n",
    "# Random data for 4 groups of 4 bars each\n",
    "data = np.random.rand(len(group_labels), 4)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Number of groups\n",
    "n_groups = len(group_labels)\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 1/(1+len(subcategories))\n",
    "\n",
    "# The x location for the groups\n",
    "indices = np.arange(n_groups)\n",
    "\n",
    "# Plotting each group\n",
    "for i, validity_type in enumerate(subcategories):\n",
    "\n",
    "    data = [validity_dict[validity_type][best_epoch] for dataset_name, validity_dict in acc_to_plot[\"validity_fraction\"].items()]\n",
    "    # The x location for the bars within each group\n",
    "    bar_positions = indices + i * bar_width\n",
    "    plt.bar(bar_positions, data, width=bar_width, label=subcategories[i], color=colors[i])\n",
    "\n",
    "# Setting the x-ticks and labels for each group\n",
    "plt.xticks(indices + bar_width * 1.5, group_labels)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Fraction valid')\n",
    "plt.title('Valid split & SMILES')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _---------------Plots during training-------------------_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average metrics during training\n",
    "\n",
    "Get the average over PROTACs for an epoch, dataset, and metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_include_in_plot = [\"Accuracy\"] #Atoms_wrong, Accuracy, Precision, Recall, F1, \n",
    "\n",
    "structures_to_include_in_plot = [\"PROTAC\", \"POI\", \"Linker\", \"E3\", \"LIGANDS\"]\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_avg\n",
    "    std_to_plot = measures_std\n",
    "else:\n",
    "    acc_to_plot = aggregated_output\n",
    "keys = list(acc_to_plot['loss'].keys())\n",
    "train_dataset_name = keys[0]\n",
    "val_dataset_name = keys[1]\n",
    "\n",
    "structure_type_to_color = {\"PROTAC\": 'red', 'POI': 'red', 'LINKER': 'black', 'E3': 'blue', 'LIGANDS': 'blue', 'LIGANDS+LINKER': 'purple'}\n",
    "dataset_to_color = {\"Train\": 'black', \"train_CV\": 'black', \"Validation\": 'green', 'val_CV': 'green', \"Test PROTAC\": 'purple', \"Test POI\": 'red', \"Test Linker\": 'gray', \"Test E3\": 'blue', 'Dummy': 'orange'}\n",
    "\n",
    "structure_type_to_label = {\"PROTAC\": \"PROTAC\", \"LIGANDS\": \"Ligands & Linker\", \"POI\": \"Warhead\"}\n",
    "\n",
    "done=False\n",
    "\n",
    "\n",
    "for dataset_idx, dataset_name in enumerate(acc_to_plot['metrics'].keys()):\n",
    "    for accuracy_origin in acc_to_plot['metrics'][dataset_name].keys():\n",
    "\n",
    "        if accuracy_origin != \"model\":\n",
    "            continue\n",
    "\n",
    "\n",
    "        #Make a plot for all accuracies\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('Epochs', color=\"black\")\n",
    "        ax1.set_ylabel('Node accuracy', color=\"black\", rotation='vertical')\n",
    "\n",
    "        #ax1.yaxis.set_label_coords(-.18, 0.5)\n",
    "\n",
    "        #Fix x-axis and get adaptive tick step size\n",
    "        x = list(range(1-int(train_params[\"compute_pretrained_values\"]),len(acc_to_plot['loss'][train_dataset_name])+1-int(train_params[\"compute_pretrained_values\"])))\n",
    "        ax1.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "        allowed_tick_sizes = [1, 2, 5, 10, 25, 50, 100]\n",
    "        desired_num_tick_steps = 10\n",
    "        deviation_num_tick_steps = [abs(len(x)//tick_size-desired_num_tick_steps) for tick_size in allowed_tick_sizes]\n",
    "        chosen_tick_step_size = allowed_tick_sizes[deviation_num_tick_steps.index(min(deviation_num_tick_steps))]\n",
    "        fig.gca().xaxis.set_major_locator(mticker.MultipleLocator(chosen_tick_step_size))\n",
    "\n",
    "        accuracy_plots_list = []\n",
    "        loss_plot_list = []\n",
    "        plotted_dummy_metrics = []\n",
    "        for structure_type in acc_to_plot['metrics'][dataset_name][accuracy_origin].keys():\n",
    "            if structure_type not in structures_to_include_in_plot:\n",
    "                continue\n",
    "\n",
    "            for metrics_type, metrics in acc_to_plot['metrics'][dataset_name][accuracy_origin][structure_type].items():\n",
    "                if metrics_type not in metrics_to_include_in_plot:\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "\n",
    "                #if isinstance(metrics, dict) or len(metrics) == 0:\n",
    "                #    continue\n",
    "                #print(metrics)\n",
    "                accuracy_plots_list.append(ax1.plot(x, metrics.values(), color=structure_type_to_color[structure_type], label= structure_type_to_label[structure_type])) #  f'{accuracy_origin}_{structure_type}_{metrics_type}'\n",
    "        \n",
    "        if True:\n",
    "            if True:\n",
    "                if len(metrics_to_include_in_plot)>1:\n",
    "                    dummy_label = f'Dummy_{metrics_type}'\n",
    "                else:\n",
    "                    dummy_label = \"Dummy\"\n",
    "                if dummy_label not in plotted_dummy_metrics:\n",
    "                    dummy_values = list(acc_to_plot[\"metrics\"][\"Dummy\"][accuracy_origin][structure_type][metrics_type].values())\n",
    "                    average_dummy_value_list = [avg(dummy_values)] * len(dummy_values)\n",
    "                    accuracy_plots_list.append(ax1.plot(x, average_dummy_value_list, color=\"orange\", label=dummy_label)) #  f'{accuracy_origin}_{structure_type}_{metrics_type}'\n",
    "                    plotted_dummy_metrics.append(dummy_label)\n",
    "\n",
    "        if model_crossfold:\n",
    "            x_arr = np.array(x)\n",
    "            for structure_type in acc_to_plot['metrics'][dataset_name][accuracy_origin].keys():\n",
    "                if structure_type not in structures_to_include_in_plot:\n",
    "                    continue\n",
    "\n",
    "                avg_tmp_dict = acc_to_plot['metrics'][dataset_name][accuracy_origin][structure_type]\n",
    "                std_tmp_dict = std_to_plot['metrics'][dataset_name][accuracy_origin][structure_type]\n",
    "                for (metrics_type, avg_vals), (metrics_type, std_vals) in zip(avg_tmp_dict.items(), std_tmp_dict.items()):\n",
    "                    if metrics_type not in metrics_to_include_in_plot:\n",
    "                        continue\n",
    "                    \n",
    "                    acc_arr = np.array(list(avg_vals.values()))\n",
    "                    std_arr = np.array(list(std_vals.values()))\n",
    "                    #print(acc_arr)\n",
    "                    #print(avg_tmp_dict)\n",
    "                    ax1.fill_between(x_arr, acc_arr-std_arr, acc_arr+std_arr, color=structure_type_to_color[structure_type], alpha=0.3)\n",
    "        \n",
    "\n",
    "        ax1.tick_params(axis='y', labelcolor=\"black\")\n",
    "        ax1.set_ylim(bottom=0, top=1)\n",
    "        ax1.set_xlim(left=min(x), right=max(x))\n",
    "        #ax1.legend(loc='lower left')\n",
    "        ax1.set_title(label=f\"Node accuracy of {accuracy_origin} for {dataset_name} dataset\\ndescriptors: {[node_descriptors] + model.graph_descriptor_list}\")\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        if dataset_idx<2:\n",
    "            for _, dataset_name_for_loss in enumerate(acc_to_plot['metrics'].keys()): \n",
    "                loss = acc_to_plot['loss'][dataset_name_for_loss].values()\n",
    "                if avg(loss) == 0:\n",
    "                    continue\n",
    "\n",
    "                loss_plot_list.append(ax2.plot(x, loss, color=dataset_to_color[dataset_name_for_loss], linestyle='dotted'))\n",
    "\n",
    "        if len(loss_plot_list) > 0:\n",
    "            #lns = ax2.plot(x, train_loss, color=\"black\", linestyle='dotted', label='Loss')\n",
    "            ax2.set_yscale(value=\"log\")\n",
    "            ax2.set_ylabel('Loss', color=\"black\", rotation='vertical')  # we already handled the x-label with ax1\n",
    "            #ax2.yaxis.set_label_coords(1.12, 0.5)\n",
    "            ax2.tick_params(axis='y')\n",
    "\n",
    "        ax3 = ax1.twinx()\n",
    "        ax3.set_yticks([])\n",
    "        ax4_dummy = ax1.twinx()\n",
    "        ax4_dummy.set_yticks([])\n",
    "\n",
    "\n",
    "        legend_positions = [1-((len(accuracy_plots_list)+1)*0.03)]\n",
    "        available_axies = [ax1, ax2, ax3, ax4_dummy]\n",
    "        legend_titles = metrics_to_include_in_plot #['Metrics']\n",
    "        plot_list = [l for l in [accuracy_plots_list, loss_plot_list] if len(l)>0]\n",
    "        if len(plot_list) == 1:\n",
    "            del available_axies[1]\n",
    "\n",
    "\n",
    "        plot_legend =True\n",
    "        if plot_legend:\n",
    "            lgnd_str = \"\"\n",
    "        else:\n",
    "            lgnd_str = \"_noLegend\"\n",
    "\n",
    "        for chosen_plot_list, legend_pos, chosen_ax, leg_title in zip(plot_list, legend_positions, available_axies, legend_titles):\n",
    "            lables = []\n",
    "            for idx, plot in enumerate(chosen_plot_list):\n",
    "                label = plot[0].get_label()\n",
    "                lables.append(label)\n",
    "                if idx == 0:\n",
    "                    plots = plot\n",
    "                else:\n",
    "                    plots = plots+plot\n",
    "            #lables = [plot.get_label() for plot in plots]\n",
    "            if plot_legend:\n",
    "                leg = chosen_ax.legend(plots, lables, loc='center left', bbox_to_anchor=(1.2, legend_pos), frameon=True, title=leg_title)\n",
    "                leg.get_frame().set_linewidth(1.0)\n",
    "                leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        fig.show()\n",
    "        #fig.savefig(f'fig_butinacutoff/NodePred_final{lgnd_str}.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "        #fig.savefig(f'fig_butinacutoff/NodePred_final{lgnd_str}.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "        done = False\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    if done:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy for each structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "sigma = 1 #smoothing\n",
    "\n",
    "\n",
    "\n",
    "dataset_to_color = {\"Train\": 'black', \"train_CV\": 'black', \"Validation\": 'green', 'val_CV': 'green', \"Test PROTAC\": 'purple', \"Test POI\": 'red', \"Test Warhead\": 'red', \"Test Linker\": 'gray', \"Test E3\": 'blue', 'Dummy': 'orange'}\n",
    "\n",
    "metrics_to_include_in_plot = [\"Accuracy\"] #Atoms_wrong, Accuracy, Precision, Recall, F1, \n",
    "structures_to_include_in_plot = [\"PROTAC\"] #, \"POI\", \"Linker\", \"E3\", \"LIGANDS\"]\n",
    "\n",
    "\n",
    "structure_type_to_label = {\"PROTAC\": \"PROTAC\", \"LIGANDS\": \"Ligands & Linker\", \"POI\": \"Warhead\"}\n",
    "\n",
    "\n",
    "plot_check_library = False\n",
    "\n",
    "if model_crossfold:\n",
    "    acc_to_plot = measures_avg\n",
    "    std_to_plot = measures_std\n",
    "else:\n",
    "    acc_to_plot = aggregated_output\n",
    "\n",
    "\n",
    "if True:\n",
    "    keys = list(acc_to_plot['loss'].keys())\n",
    "    train_dataset_name = keys[0]\n",
    "    val_dataset_name = keys[1]\n",
    "    for i, structure_type in enumerate(acc_to_plot['metrics'][train_dataset_name]['model'].keys()):\n",
    "        if structure_type not in structures_to_include_in_plot:\n",
    "            continue\n",
    "\n",
    "        #Make a plot for all accuracies\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel('Epochs', color=\"black\")\n",
    "        ax1.set_ylabel('Node accuracy', color=\"black\", rotation='vertical')\n",
    "\n",
    "        #ax1.yaxis.set_label_coords(-.18, 0.5)\n",
    "\n",
    "\n",
    "        #get adaptive tick step size\n",
    "        x = list(range(1-int(model.compute_pretrained_values),len(acc_to_plot['loss'][train_dataset_name])+1-int(model.compute_pretrained_values)))\n",
    "        x = [val for i, val in enumerate(x) if i<best_epoch]\n",
    "        ax1.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "        allowed_tick_sizes = [1, 2, 5, 10, 25, 50, 100]\n",
    "        desired_num_tick_steps = 10\n",
    "        deviation_num_tick_steps = [abs(len(x)//tick_size-desired_num_tick_steps) for tick_size in allowed_tick_sizes]\n",
    "        chosen_tick_step_size = allowed_tick_sizes[deviation_num_tick_steps.index(min(deviation_num_tick_steps))]\n",
    "        fig.gca().xaxis.set_major_locator(mticker.MultipleLocator(chosen_tick_step_size))\n",
    "\n",
    "\n",
    "        ax1.tick_params(axis='y', labelcolor=\"black\")\n",
    "        ax1.set_ylim(bottom=0, top=1)\n",
    "        ax1.set_xlim(left=min(x), right=max(x))\n",
    "        #ax1.set_title(label=f\"{metrics_to_include_in_plot} of {structure_type}\\ndescriptors: {[node_descriptors] + model.graph_descriptor_list}\")\n",
    "\n",
    "\n",
    "        accuracy_plots_list = []\n",
    "        accuracy_plots_check_library_list = []\n",
    "\n",
    "\n",
    "        for dataset_name in acc_to_plot['metrics'].keys():\n",
    "            for metric_type, acc_tmp in acc_to_plot['metrics'][dataset_name]['model'][structure_type].items():\n",
    "                if metric_type not in metrics_to_include_in_plot:\n",
    "                    continue\n",
    "                elif dataset_name not in dataset_to_color:\n",
    "                    continue\n",
    "\n",
    "                if dataset_name == \"Dummy\":\n",
    "                    dummy_values = list(acc_to_plot[\"metrics\"][\"Dummy\"][\"model\"][structure_type][metric_type].values())\n",
    "                    average_dummy_value_list = [avg(dummy_values)] * len(x)\n",
    "                    accuracy_plots_list.append(ax1.plot(x, average_dummy_value_list, color=\"orange\", label=\"Dummy\"))\n",
    "                    continue\n",
    "\n",
    "                acc_tmp = list(acc_tmp.values())\n",
    "                acc_tmp = gaussian_filter1d(acc_tmp, sigma=sigma)\n",
    "                acc_tmp = [val for i, val in enumerate(acc_tmp) if i<best_epoch]\n",
    "                accuracy_plots_list.append(ax1.plot(x, acc_tmp, color=dataset_to_color[dataset_name], label=f'{dataset_name}'))\n",
    "                \n",
    "                if plot_check_library:\n",
    "                    acc_check_library_tmp = list(acc_to_plot['metrics'][dataset_name]['model+check_library'][structure_type][metric_type].values())\n",
    "                    accuracy_plots_check_library_list.append(ax1.plot(x, acc_check_library_tmp, color=dataset_to_color[dataset_name], label=f'{dataset_name}', linestyle='dashed'))\n",
    "\n",
    "                if model_crossfold:\n",
    "\n",
    "                    std_tmp = list(std_to_plot['metrics'][dataset_name]['model'][structure_type][metric_type].values())\n",
    "                    std_tmp = gaussian_filter1d(std_tmp, sigma=sigma)\n",
    "                    std_tmp = [val for i, val in enumerate(std_tmp) if i<best_epoch]\n",
    "                    std_check_library_tmp = list(std_to_plot['metrics'][dataset_name]['model+check_library'][structure_type][metric_type].values())\n",
    "                    std_check_library_tmp = [val for i, val in enumerate(std_check_library_tmp) if i<best_epoch]\n",
    "\n",
    "                    x_arr = np.array(x)\n",
    "                    acc_tmp_np = np.array(acc_tmp)\n",
    "                    std_tmp_np = np.array(std_tmp)\n",
    "                    ax1.fill_between(x_arr, acc_tmp_np-std_tmp_np, acc_tmp_np+std_tmp_np, color=dataset_to_color[dataset_name], alpha=0.3)\n",
    "\n",
    "                    if plot_check_library:\n",
    "                        acc_check_library_tmp_np = np.array(acc_check_library_tmp)\n",
    "                        std_check_library_tmp_np = np.array(std_check_library_tmp)\n",
    "                        ax1.fill_between(x_arr, acc_check_library_tmp_np-std_check_library_tmp_np, acc_check_library_tmp_np+std_check_library_tmp_np, color=dataset_to_color[dataset_name], alpha=0.3)\n",
    "\n",
    "        loss_plot_list = []\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_yscale(value=\"log\")\n",
    "        ax2.set_ylabel('Loss', color=\"black\", rotation='vertical')  # we already handled the x-label with ax1\n",
    "        #ax2.yaxis.set_label_coords(1.12, 0.5)\n",
    "        ax2.tick_params(axis='y')\n",
    "        train_loss = list(acc_to_plot['loss'][train_dataset_name].values())\n",
    "        val_loss = list(acc_to_plot['loss'][val_dataset_name].values())\n",
    "        train_loss = gaussian_filter1d(train_loss, sigma=sigma)\n",
    "        val_loss = gaussian_filter1d(val_loss, sigma=sigma)\n",
    "        train_loss = [val for i, val in enumerate(train_loss) if i<best_epoch]\n",
    "        val_loss = [val for i, val in enumerate(val_loss) if i<best_epoch]\n",
    "        loss_plot_list.append(ax2.plot(x, train_loss, color=\"black\", linestyle='dotted', label='Train')) #marker='--'\n",
    "        loss_plot_list.append(ax2.plot(x, val_loss, color=\"green\", linestyle='dotted', label='Validation')) #marker='--'\n",
    "\n",
    "            \n",
    "\n",
    "        ax3 = ax1.twinx()\n",
    "        ax3.set_yticks([])\n",
    "        ax4_dummy = ax1.twinx()\n",
    "        ax4_dummy.set_yticks([])\n",
    "\n",
    "\n",
    "        legend_positions = [0.8, 0.35, -0.02]\n",
    "        available_axies = [ax1, ax2, ax3, ax4_dummy]\n",
    "        legend_titles = ['Accuracy', 'Model+Check Library accuracy']\n",
    "        if plot_check_library is False:\n",
    "            legend_titles.remove('Model+Check Library accuracy')\n",
    "        plot_list = [accuracy_plots_list, accuracy_plots_check_library_list, loss_plot_list]\n",
    "        plot_list = [l for l in plot_list if len(l)>0]\n",
    "        if len(plot_list) == 1:\n",
    "            del available_axies[1]\n",
    "\n",
    "        plot_legend = False\n",
    "\n",
    "        for chosen_plot_list, legend_pos, chosen_ax, leg_title in zip(plot_list, legend_positions, available_axies, legend_titles):\n",
    "            lables = []\n",
    "            for idx, plot in enumerate(chosen_plot_list):\n",
    "                label = plot[0].get_label()\n",
    "                lables.append(label)\n",
    "                if idx == 0:\n",
    "                    plots = plot\n",
    "                else:\n",
    "                    plots = plots+plot\n",
    "            lables = [plot.get_label() for plot in plots]\n",
    "            if plot_legend:\n",
    "                leg = chosen_ax.legend(plots, lables, loc='center left', bbox_to_anchor=(1.2, legend_pos), frameon=True, title=leg_title)\n",
    "                leg.get_frame().set_linewidth(1.0)\n",
    "                leg.get_frame().set_edgecolor('k')\n",
    "            #ax1.add_artist(leg)\n",
    "            #chosen_ax.legend(frameon=True)\n",
    "            figs = {structure_type: fig}\n",
    "            fig.show()\n",
    "\n",
    "        legend_str=\"\"\n",
    "        if not plot_legend:\n",
    "            legend_str=\"_noLegend\"\n",
    "        #fig.savefig(f'fig_finaltraincurves/{model.model_type}_{identifying_comment}_{structure_type}_{metrics_to_include_in_plot}{legend_str}.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "        #fig.savefig(f'fig_finaltraincurves/{model.model_type}_{identifying_comment}_{structure_type}_{metrics_to_include_in_plot}{legend_str}.png', format='png', dpi=1200, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- Plot predicted graphs ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_library = False\n",
    "\n",
    "num_protacs_per_set = 5\n",
    "\n",
    "chosen_dataset = \"Validation\"\n",
    "\n",
    "fp_function = compute_countMorgFP\n",
    "\n",
    "e3_database_fps = None #compute_countMorgFP(e3_library)\n",
    "poi_database_fps = None #compute_countMorgFP(poi_library)\n",
    "\n",
    "plot_postprocessed_graphs = False\n",
    "\n",
    "\n",
    "protac_smi_to_plot = []#['COc1ccc(OC)c2c1c(OC)cc1c(=O)cc(-c3ccc(CCn4cc(-c5ccc6c(c5)C(c5ccc(Cl)cc5)=NC5(CC5)c5nnc(C)n5-6)cn4)cc3)oc12',\n",
    "                     # 'COc1ccc(Cl)c(S(=O)(=O)Nc2ccc(-c3nc(OCC4CN(c5ccc(N=Nc6ccc(C(=O)c7ccc(-c8cc(=O)c9cc(OC)c%10c(OC)ccc(OC)c%10c9o8)cc7)cc6)cc5)CCO4)c4c(C)n[nH]c4n3)cc2)c1']#['COc1ccc(OC)c2c1c(OC)cc1c(=O)cc(-c3ccc(NC=NC4CC5(C)CC(Oc6ccc(C#N)c(Cl)c6)CC5(C)C4)cc3)oc12',\n",
    "                     # 'Cc1ccc(F)c(S(=O)(=O)Nc2ccc(-c3nc(OCC4CN(C(=O)c5cnc(N6CCN(CCCCCN=COc7ccc8c(c7)CCCN8C(=O)CCl)CC6)nc5)CCO4)c4cn[nH]c4n3)cc2)c1']\n",
    "\n",
    "\n",
    "for dataset_name, dataset  in datasets_dict.items():\n",
    "    if dataset_name != chosen_dataset:\n",
    "        continue\n",
    "\n",
    "    # Create a figure with 'num_protacs_per_set' rows and 3 columns for each dataset\n",
    "    num_columns = 2 + int(plot_postprocessed_graphs) + int(use_library)\n",
    "    fig, axarr = plt.subplots(num_protacs_per_set, num_columns, figsize=(num_columns*5, num_protacs_per_set * 5))\n",
    "\n",
    "    loader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(num_protacs_per_set):\n",
    "        protac_idx = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "        #if len(protac_idx_to_plot)>0:\n",
    "        #    if protac_idx not in protac_idx_to_plot:\n",
    "        #        continue\n",
    "\n",
    "        j = 0\n",
    "        for batch in loader:\n",
    "            \n",
    "            if protac_smi_to_plot != []:\n",
    "                if batch.smiles[0] in protac_smi_to_plot:       #assumes batch_size == 1\n",
    "                    protac_smi_to_plot.remove(batch.smiles[0])\n",
    "                    print(f'SMILES was found from in the SMILES_to_plot_list: {batch.smiles[0]}')\n",
    "                    protac_idx = j\n",
    "                    break\n",
    "            elif j==protac_idx:\n",
    "                break\n",
    "            else:\n",
    "                j += 1\n",
    "\n",
    "        \n",
    "        batch = batch.to(model.device)\n",
    "\n",
    "\n",
    "        ground_truth_colors = ['red' if label == 0 else 'gray' if label == 1 else 'blue' for label in batch.substructure_labels]\n",
    "\n",
    "\n",
    "        G, pos = make_graph_with_pos(batch.smiles[0])\n",
    "     \n",
    "\n",
    "        # Plot ground truth on the left column\n",
    "        nx.draw_networkx(G, pos=pos, ax=axarr[i, 0], node_color=ground_truth_colors, with_labels=False, node_size=50)\n",
    "        #axarr[i, 0].set_title(f\"Ground truth {dataset_name} {protac_idx}\")\n",
    "        axarr[i, 0].axis('equal')\n",
    "\n",
    "\n",
    "        if dataset_name == \"Dummy\":\n",
    "            randomize_y = True\n",
    "        else:\n",
    "            randomize_y = False\n",
    "        y_type, y_location, predictions_and_prob, boundary_bond_probs_dataset = model.batch_to_output_and_classpredictions(batch=batch, e3_database_fps=e3_database_fps, poi_database_fps=poi_database_fps, fp_function=fp_function, randomize_y=randomize_y)\n",
    "\n",
    "\n",
    "        class_predictions = predictions_and_prob[\"model\"][0]\n",
    "\n",
    "\n",
    "        predicted_colors = ['red' if label == 0 else 'gray' if label == 1 else 'blue' for label in class_predictions]\n",
    "        \n",
    "        nx.draw_networkx(G, pos=pos, ax=axarr[i, 1], node_color=predicted_colors, with_labels=False, node_size=50)\n",
    "        #axarr[i, 1].set_title(f\"Predicted {dataset_name} {protac_idx}\")\n",
    "        axarr[i, 1].axis('equal')\n",
    "\n",
    "        if use_library:\n",
    "            class_predictions_library = predictions_and_prob[\"model+check_library\"][0]\n",
    "            predicted_colors_library = ['red' if label == 0 else 'gray' if label == 1 else 'blue' for label in class_predictions_library]\n",
    "        \n",
    "            nx.draw_networkx(G, pos=pos, ax=axarr[i, 2], node_color=predicted_colors_library, with_labels=False, node_size=50)\n",
    "            axarr[i, 2].set_title(f\"Predicted & librarychecked {dataset_name} {protac_idx}\")\n",
    "            axarr[i, 2].axis('equal')\n",
    "        \n",
    "\n",
    "      \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #fig.savefig(f'fig_results/{model.model_type}_{identifying_comment}_{chosen_dataset}_{split_idx}.svg', format='svg', dpi=1200, bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
