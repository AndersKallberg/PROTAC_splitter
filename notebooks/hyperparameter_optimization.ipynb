{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1000, 'display.width', 2000, 'display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "\n",
    "from protacdataset import ProtacLoader\n",
    "from protacsplitter import PROTACSplitter\n",
    "from data_curation_augmentation_splitting_functions import (compute_countMorgFP)\n",
    "from pipeline_functions import (aggregate_output_all_epochs, \n",
    "                                get_best_epoch,\n",
    "                                avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Loads training and validation data\n",
    "\n",
    "Specify the butina cutoff.\n",
    "\n",
    "Specify the path by the number of protacs \"n\" in the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train: 952, 2856, 9520 #used sizes in the thesis\n",
    "#Val. : 238, 714,  2380\n",
    "\n",
    "\n",
    "butina_cutoff = \"0.33\" #0.0, 0.33, 0.67\n",
    "\n",
    "path_substr = {\n",
    "    \"Train\":            {'id': \"train\",             'n': \"952\",    'butina': butina_cutoff},\n",
    "    \"Validation\":       {'id': \"val\",               'n': \"238\",    'butina': butina_cutoff},\n",
    "}\n",
    "\n",
    "dataset_paths = {dataset_name: f\"../data/augmented/{substr_dict['id']}_{substr_dict['n']}_ButinaClusterCutoff_{substr_dict['butina']}.csv\" for dataset_name, substr_dict in path_substr.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chosen_dataset_paths = dataset_paths\n",
    "\n",
    "dataset_names = chosen_dataset_paths.keys()\n",
    "\n",
    "\n",
    "\n",
    "model_type=\"link_pred\" # node_pred link_pred boundary_pred\n",
    "node_descriptors = \"rdkit\" #ones, empty, rdkit\n",
    "graph_descriptors = [ \"betweenness\", \"closeness\"] #[\"betweenness\", \"eigenvector\"] etc. \"betweenness\", \"closeness\", \"local_eigenvectors_x\"\n",
    "model_crossfold=False\n",
    "save_datasets = False \n",
    "load_datasets = False\n",
    "precompute_splits=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtacDataset_loader = ProtacLoader(dataset_paths=chosen_dataset_paths, model_type=model_type, node_descriptors=node_descriptors, graph_descriptors=graph_descriptors, model_crossfold=model_crossfold)\n",
    "if not load_datasets:\n",
    "    datasets_dict = ProtacDataset_loader.initialize_datasets(dataframes=ProtacDataset_loader.load_dataframes(),\n",
    "                                                                num_crossfolds=1, precompute_splits=precompute_splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, max_epochs=15, model_type=model_type):\n",
    "\n",
    "    # --------------------- Training parameters ---------------------\n",
    "\n",
    "    #Libraries set to None, as they are not important during optimization\n",
    "    e3_library = None #pd.read_csv('../../data/e3_trainval_substructures_without_attachment.csv')[\"E3 SMILES\"].to_list()\n",
    "    poi_library = None #pd.read_csv('../../data/poi_trainval_substructures_without_attachment.csv')[\"POI SMILES\"].to_list()\n",
    "\n",
    "    #Early stopping parameters\n",
    "    val_early_stopping = True #model looks back 2*n epochs to decide if it shall continue or stop, depending on validation loss. IF median has increased => Stop.\n",
    "    median_over_n_val_losses = None\n",
    "    min_over_n_val_losses = None\n",
    "\n",
    "    shift = 0.6 # vary this by hand for different models to set various early stopping criteria. Set to 1 to disable this feature\n",
    "    stop_if_val_acc_below_x_at_n_list = [ #{'val_frac_criteria': 0.42, 'n_epochs': 1}, # good cutoff for node predictions\n",
    "                                                {'val_frac_criteria': 0.5-shift, 'n_epochs': 1}, #{'val_frac_criteria': 0.7, 'n_epochs': 2},\n",
    "                                                {'val_frac_criteria': 0.65-shift, 'n_epochs': 2}, # {'val_frac_criteria': 0.8, 'n_epochs': 3}, \n",
    "                                                {'val_frac_criteria': 0.7-shift, 'n_epochs': 3},# {'val_frac_criteria': 0.9, 'n_epochs': 4}, \n",
    "                                                {'val_frac_criteria': 0.75-shift, 'n_epochs': 4},#{'val_frac_criteria': 0.65, 'n_epochs': 8},\n",
    "                                                {'val_frac_criteria': 0.8-shift, 'n_epochs': 5},\n",
    "                                                {'val_frac_criteria': 0.825-shift, 'n_epochs': 6},\n",
    "                                                {'val_frac_criteria': 0.85-shift, 'n_epochs': 7},\n",
    "                                                {'val_frac_criteria': 0.875-shift, 'n_epochs': 8},\n",
    "                                                {'val_frac_criteria': 0.9-shift, 'n_epochs': 9}] #[x,n]   #if below 60% accuracy at 5 epochs, abort: x% at n epochs\n",
    "    \n",
    "    # Model training parameters\n",
    "    compute_pretrained_values = False \n",
    "    compute_rand_accuracy = False\n",
    "\n",
    "    # --------------------- Hyperparameters ---------------------\n",
    "    \n",
    "    num_layers = 9 #trial.suggest_int('num_layers', 3, 9)  \n",
    "    layer_sizes = trial.suggest_categorical('layer_dims', [100, 250, 500, 750, 1000])  # Allowed layer sizes\n",
    "    layer_dims = [layer_sizes]*num_layers # [trial.suggest_categorical(f'layer_dim_{i}', layer_sizes) for i in range(num_layers)]\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5) \n",
    "\n",
    "    gnn_layer_type = trial.suggest_categorical('gnn_layer_type', ['GraphConv', 'GCNConv', 'SAGEConv', 'GATConv', 'TransformerConv']) \n",
    "\n",
    "    use_batch_normalization = trial.suggest_categorical('use_batch_normalization', [True, False])\n",
    "    use_skip_connections = trial.suggest_categorical('use_skip_connections', [True, False])\n",
    "    use_graph_normalization = trial.suggest_categorical('use_graph_normalization', [True, False])\n",
    "    use_edge_information = True if gnn_layer_type == 'TransformerConv' else False\n",
    "    output_depth = trial.suggest_int('output_depth', 2, 4) # if model_type == 'link_pred' else 3\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 1e-2, log=True) \n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [1, 8, 64])\n",
    "\n",
    "    weight_class_loss = 0.1 \n",
    "    \n",
    "    # --------------------- Model initialization and training ---------------------\n",
    "    \n",
    "    #Initialize model\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #\"cpu\") ## cuda makes the size of the network no longer matter in terms of epoch-time?! (64=1024 dimensions) On cpu it is 7 s vs 1min 30 seconds. GPU: 14 s vs 14 s\n",
    "        \n",
    "    train_key = \"Train\"\n",
    "    val_key = \"Validation\"\n",
    "    node_feature_dim = datasets_dict[train_key].num_node_features\n",
    "\n",
    "    output_layer_config = [{\n",
    "            'type': \"linear_symmetric\",  # Indicates symmetric processing but not global\n",
    "            'in_features': -1,  # Input features to the first output layer\n",
    "            'intermediate_features': layer_dims[0],  # Size for the middle layer in the sequence\n",
    "            'out_features': 3,  # Size for the final classification/prediction layer\n",
    "            'depth': output_depth,  # Total number of layers in this sequence\n",
    "        }]\n",
    "\n",
    "\n",
    "    boundary_layer_config = [{\n",
    "            'type': \"linear_symmetric\",  # Indicates the use of symmetric and global adjustments\n",
    "            'in_features': -1,  # Input features to the first boundary layer\n",
    "            'intermediate_features': layer_dims[0],  # Intermediate layer size (if applicable)\n",
    "            'out_features': 2,  # Final output size for boundary prediction\n",
    "            'depth': output_depth,  # Total number of layers in this sequence\n",
    "        }]\n",
    "\n",
    "\n",
    "    init_params = {\n",
    "        'model_type': model_type,\n",
    "        'node_feature_dim': node_feature_dim, \n",
    "        'device': device,\n",
    "        'num_predicted_classes': 3,\n",
    "        \n",
    "        'num_layers': num_layers,\n",
    "        'layer_dims': layer_dims,\n",
    "        'final_layer_dim': layer_dims[-1] if model_type==\"link_pred\" else 3,\n",
    "        'gnn_layer_type': gnn_layer_type,\n",
    "        \n",
    "        #TransformerConv parameters. Currently set to default values.\n",
    "        'TransformerConvHeads': 1,\n",
    "        'TransformerConvBeta': False,\n",
    "        'TransformerConvDropout': 0,\n",
    "\n",
    "        #Possible to add the L1 and L2 norm of model parameters to the loss (it is normalized (divided) by the number of modelparameters before)\n",
    "        'regularization_types': [], # ['L1_model_params', 'L2_model_params']\n",
    "        'dropout_rate': dropout_rate,\n",
    "        \n",
    "        'use_skip_connections': use_skip_connections,\n",
    "        'use_graph_normalization': use_graph_normalization,\n",
    "        'use_edge_information': use_edge_information,\n",
    "        'use_batch_normalization': use_batch_normalization,\n",
    "\n",
    "        'output_layer_config': output_layer_config,\n",
    "        'boundary_layer_config': boundary_layer_config\n",
    "    }    \n",
    "\n",
    "    model = PROTACSplitter(init_params=init_params)\n",
    "     \n",
    "    \n",
    "    # --------------------- Assemble training parameters ---------------------\n",
    "\n",
    "\n",
    "    \n",
    "    train_params = {\n",
    "        'datasets_dict': {train_key: datasets_dict[train_key], val_key: datasets_dict[val_key]},\n",
    "        'optimizer': optim.Adam,\n",
    "        'lr': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'criterion': nn.CrossEntropyLoss(reduction='sum'),\n",
    "        'epochs': max_epochs,\n",
    "        'max_epochs': max_epochs,\n",
    "        'val_early_stopping': val_early_stopping,\n",
    "        'median_over_n_val_losses': median_over_n_val_losses,\n",
    "        'min_over_n_val_losses': min_over_n_val_losses,\n",
    "        'stop_if_val_acc_below_x_at_n_list': stop_if_val_acc_below_x_at_n_list,\n",
    "        'print_every_n_epochs': 1,\n",
    "        'compute_pretrained_values': compute_pretrained_values,\n",
    "        'compute_rand_accuracy': compute_rand_accuracy,\n",
    "        'e3_library': e3_library,\n",
    "        'poi_library': poi_library,\n",
    "        'fp_function': compute_countMorgFP,\n",
    "        'param_to_opt': ['accuracy'], # only compute the accuracy when optimizing hyperparameters\n",
    "        'weight_class_loss': weight_class_loss #weighting between row-loss (bondclass-loss) and column-loss.\n",
    "    }\n",
    "\n",
    "\n",
    "    # --------------------- Train model and get output ---------------------\n",
    "\n",
    "    \n",
    "\n",
    "    #Training\n",
    "    model.to(device=device)\n",
    "    output = model.train_model(train_params=train_params)\n",
    "    \n",
    "\n",
    "    #Get optimization metric\n",
    "    aggregated_output = aggregate_output_all_epochs(output=output)\n",
    "    best_epoch = get_best_epoch(output= aggregated_output, \n",
    "                       dataset= model.val_set_name, \n",
    "                       accuracy_origin=\"model\", \n",
    "                       structure=\"PROTAC\", \n",
    "                       metric_type=\"Accuracy\",\n",
    "                       model_crossfold = model_crossfold)\n",
    "    \n",
    "    best_val_acc = avg(output['metrics'][model.val_set_name][\"model\"][\"PROTAC\"][\"Accuracy\"][best_epoch]) #Optimize for validation accuracy\n",
    "    \n",
    "    return best_val_acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a folder named \"pickle_optuna\" to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_study_paths = []\n",
    "if True:\n",
    "    \n",
    "    n_trials = 1000\n",
    "    pickle_str = f'{model_type}_study1.pickle'\n",
    "    study_path = f'pickle_optuna/{pickle_str}'\n",
    "    \n",
    "    if study_path != '':\n",
    "        for _ in range(n_trials):\n",
    "            if not os.path.exists(study_path):\n",
    "                study = optuna.create_study(direction='maximize') # Use 'minimize' if you are returning a loss\n",
    "                study.optimize(objective, n_trials=1)\n",
    "                with open(study_path, 'wb') as file:\n",
    "                    pickle.dump(study, file)\n",
    "            else:\n",
    "                with open(study_path, 'rb') as file:\n",
    "                    study = pickle.load(file)\n",
    "                study.optimize(objective, n_trials=1)\n",
    "                with open(study_path, 'wb') as file:\n",
    "                    pickle.dump(study, file)\n",
    "    else:\n",
    "        study = optuna.create_study(direction='maximize') # Use 'minimize' if you are returning a loss\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display parameters of best trials\n",
    "\n",
    "load_pickled_study = True\n",
    "\n",
    "if load_pickled_study:\n",
    "\n",
    "    #load study\n",
    "    if load_pickled_study:\n",
    "        pickle_str = 'your_study_name.pickle' # ''\n",
    "        study_path = f'pickle_optuna/{pickle_str}'\n",
    "        if os.path.exists(study_path):\n",
    "            with open(study_path, 'rb') as file:\n",
    "                study = pickle.load(file)\n",
    "        \n",
    "    #print dataframe\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_df_sorted = trials_df.sort_values(by=[\"value\"], ascending=False)\n",
    "    print(\"Best trials and their parameters:\")\n",
    "    print(len(trials_df))\n",
    "    display(trials_df_sorted.head(20))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display various visualizations of the trial from optuna\n",
    "\n",
    "load_pickled_study = False\n",
    "\n",
    "if load_pickled_study:\n",
    "\n",
    "\n",
    "\n",
    "    #load study\n",
    "    if load_pickled_study:\n",
    "        pickle_str = 'your_study_name.pickle' # ''\n",
    "        study_path = f'pickle_optuna/{pickle_str}'\n",
    "        if os.path.exists(study_path):\n",
    "            with open(study_path, 'rb') as file:\n",
    "                study = pickle.load(file)\n",
    "        \n",
    "    #print dataframe\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_df_sorted = trials_df.sort_values(by=[\"value\"], ascending=False)\n",
    "    print(\"Best trials and their parameters:\")\n",
    "    display(trials_df_sorted.head(10))\n",
    "        \n",
    "    #plot optuna plots\n",
    "    best_params = study.best_params\n",
    "    study_parameters = []\n",
    "    for s in study.get_trials():\n",
    "        for k, v in s.params.items():\n",
    "            if k not in study_parameters:\n",
    "                study_parameters.append(k)\n",
    "    display(optuna.visualization.plot_parallel_coordinate(study))\n",
    "    study_parameters_2 = study_parameters.copy()\n",
    "    study_parameters_2.remove('lr')\n",
    "    display(optuna.visualization.plot_param_importances(study, params=study_parameters))\n",
    "    display(optuna.visualization.plot_slice(study, params=study_parameters))\n",
    "    display(optuna.visualization.plot_contour(study))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #plot acc vs lr, colored by batch size\n",
    "    optuna_study_val_accs = []\n",
    "    optuna_study_param_vals = []\n",
    "    optuna_study_param = 'lr'\n",
    "    optuna_study_param_vals_to_color_by = []\n",
    "    optuna_study_param_to_color_by = 'batch_size'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for s in study.get_trials():\n",
    "        optuna_study_val_accs.append(s.values)\n",
    "        optuna_study_param_vals.append(s.params[optuna_study_param])\n",
    "        optuna_study_param_vals_to_color_by.append(s.params[optuna_study_param_to_color_by])\n",
    "\n",
    "    optuna_study_param_vals_to_color_by_set = sorted(set(optuna_study_param_vals_to_color_by))\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, len(optuna_study_param_vals_to_color_by_set)))\n",
    "\n",
    "    labels_in_legend =[]\n",
    "    for trial_param, trial_val_acc, optuna_study_param_to_color_by in zip(optuna_study_param_vals, optuna_study_val_accs, optuna_study_param_vals_to_color_by):\n",
    "        color = colors[optuna_study_param_vals_to_color_by_set.index(optuna_study_param_to_color_by)]\n",
    "        label = f'Batch Size: {optuna_study_param_to_color_by}'\n",
    "        if label in labels_in_legend:\n",
    "            label=''\n",
    "        plt.scatter([trial_param], [trial_val_acc], color=color, label=label)\n",
    "        if label not in labels_in_legend and label != '':\n",
    "            labels_in_legend.append(label)\n",
    "\n",
    "    plt.xlabel('Learning Rate (lr)')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Validation Accuracy vs Learning Rate for Different Batch Sizes')\n",
    "    plt.xscale('log')  # Since lr values are usually in a log scale\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles,labels, loc='upper left')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-protac-toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
